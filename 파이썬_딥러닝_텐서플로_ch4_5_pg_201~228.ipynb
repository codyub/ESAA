{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwd4NKZDkk7zDFo6l4u/Fk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codyub/ESAA/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C_ch4_5_pg_201~228.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05 개/고양이 분류\n",
        "- 이미지 데이터셋을 32장, 64장, 128장 등 배치 단위로 나눈 다음 배치 한 개를 읽어와 딥러닝 모델에 주입하면 메모리 부담 없이 학습할 수 있다.\n",
        "- 전체 데이터 셋을 전부 모델에 입력할 때까지 배치 단위로 읽어오고 주입하는 과정을 반복한다.\n",
        "- Image Data Generator"
      ],
      "metadata": {
        "id": "BzMeoFNcTH0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-1-1 데이터셋 다운로드\n",
        "# 5-1-2 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "32pcwAaXThZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt"
      ],
      "metadata": {
        "id": "qavBBbFVX6F_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델을 컴파일하고 50 데포크 동안 훈련"
      ],
      "metadata": {
        "id": "TVRjiqMuToCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 모델 컴파일\n",
        "# tc_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # 모델 훈련\n",
        "# tc_history = tc_model.fit(train_aug, validation_data=valid_aug, epochs=50)"
      ],
      "metadata": {
        "id": "JGDzNRChTqjo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-1-3 구글 드라이브 마운트"
      ],
      "metadata": {
        "id": "YTy_Mx6wTFTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#import os\n",
        "#os.chdir(\"/content/drive/MyDrive/ESAA/2023-1/필사/data/dogsandcats/\") # working directory를 설정함."
      ],
      "metadata": {
        "id": "Y8WtXiLBTFxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e91239-1163-4e88-d010-db0a4ee8262a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-1-4 압축 파일 해제\n",
        "- 파일을 구글 드라이브에 저장하지 않음. 왜냐하면 구글 드라이브로 읽으면 읽어오고 저장하는 속도가 매우 느리기 때문임."
      ],
      "metadata": {
        "id": "mT15jjrLcECI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "trLXnhP1HytF"
      },
      "outputs": [],
      "source": [
        "# 압축 파일의 위치 (구글 드라이브 - 내 드라이브 위치)\n",
        "drive_path = '/content/drive/MyDrive/ESAA/2023-1/필사/data/'\n",
        "source_filename = drive_path + 'dogsandcats.zip'\n",
        "\n",
        "# 저장할 경로\n",
        "extract_folder = \"dataset/\"   # 코랩 환경에 임시 저장\n",
        "\n",
        "# 압축 해제\n",
        "import shutil\n",
        "shutil.unpack_archive(source_filename,extract_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 셋, 검증 셋 저장위치 지정\n",
        "train_dir = extract_folder + \"training_set/training_set\"\n",
        "valid_dir = extract_folder + \"test_set/test_set\"\n",
        "print(train_dir)\n",
        "print(valid_dir)"
      ],
      "metadata": {
        "id": "YtCLvcnNci5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83008a96-84c0-4b56-dca5-f9e502300da0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset/training_set/training_set\n",
            "dataset/test_set/test_set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-2 모델 학습\n",
        "# 5-2-1 ImageDataGenerator\n",
        "- rescale 옵션을 지정해 이미지 각 픽셀의 값을 0~1 범위로 정규화\n",
        "- 생성된 제너레이터 객체를 image_gen 변수에 할당"
      ],
      "metadata": {
        "id": "9UWCDxRccjNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터 제너레이터 정의 (Augmentation 미적용)\n",
        "image_gen = ImageDataGenerator(rescale=(1/255.))\n",
        "image_gen"
      ],
      "metadata": {
        "id": "ylfqottCdChY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bf490f-f662-48bd-ac74-061e1eae63de"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.image.ImageDataGenerator at 0x7fa1d02b6980>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-2-2 flow_from_directory 함수\n",
        "- 지정한 폴더에서 이미지를 가져와 반복 이터레이션이 가능하도록 데이터셋을 처리\n",
        "\n",
        "ex. cat 폴더에 들어 있는 고양이 이미지를 (224,224) 크기로 리사이징, 클래스 레이블은 cats에 해당하는 정수로 레이블 인코딩, 이미진는 32장씩 묶어서 하나의 배치 구성\n",
        "\n",
        "- train_dir: 훈련 셋 저장\n",
        "- batch_size: 배치를 구성하는 이미지 개수 32\n",
        "- target_size: 저장될 이미지의 픽셀 사이즈\n",
        "- classes: 클래스 레이블\n",
        "- class_mode: 이진 분류 문제를 나타내는 모드, 랜덤 시드 값 지정"
      ],
      "metadata": {
        "id": "ix9OmQ8hdC2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flow_from_directory 함수로 폴더에서 이미지 가져와서 제너레이터 객체로 정리\n",
        "train_gen = image_gen.flow_from_directory(train_dir,\n",
        "                                          batch_size=32,\n",
        "                                          target_size=(224, 224),\n",
        "                                          classes=['cats','dogs'],\n",
        "                                          class_mode = 'binary',\n",
        "                                          seed=2020)\n",
        "\n",
        "valid_gen = image_gen.flow_from_directory(valid_dir,\n",
        "                                          batch_size=32,\n",
        "                                          target_size=(224, 224),\n",
        "                                          classes=['cats','dogs'],\n",
        "                                          class_mode = 'binary',\n",
        "                                          seed=2020)"
      ],
      "metadata": {
        "id": "36yeFITDdmIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a88311-978b-449e-be03-1f660e2040f9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 0 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 왜 로드가 되지 않는걸까?"
      ],
      "metadata": {
        "id": "Wngs-GdkwWcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1개의 배치를 선택해서 배치 안에 들어있는 32개의 이미지를 정답 클래스 레이블과 함께 출력하면 다음과 같음"
      ],
      "metadata": {
        "id": "vqkvWY34dmxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 이미지 출력\n",
        "class_labels = ['cats', 'dogs']\n",
        "batch = next(train_gen)\n",
        "images, labels = batch[0], batch[1]\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(32):\n",
        "\n",
        "    ax = plt.subplot(4, 8, i + 1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(class_labels[labels[i].astype(np.int)])\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENQ0a3Bzduyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-2-3 모델 훈련\n",
        "- 배치 정규화 / 합성곱 / 풀링 으로 구성된 단위 블럭을 3개 반복해 이미지로부터 다양한 피처를 추출하고, 최종 분류기로 Dense 레이어를 사용\n",
        "- 최종 출력 레이어는 노드 1개를 갖고 활성화 함수는 sigmoid"
      ],
      "metadata": {
        "id": "DBtA_DzgdvFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential API를 사용하여 샘플 모델 생성\n",
        "\n",
        "def build_model():\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "\n",
        "        # Convolution 층\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "        # Classifier 출력층\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model()"
      ],
      "metadata": {
        "id": "fxstYhwNgEZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 옵티마이저, 손실함수 지정\n",
        "- 모델 컴파일, 20에포크 훈련"
      ],
      "metadata": {
        "id": "oHHE8RNSgEqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일\n",
        "model.compile(optimizer=tf.optimizers.Adam(lr=0.001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history = model.fit(train_gen, validation_data=valid_gen, epochs=20)"
      ],
      "metadata": {
        "id": "HenWxH-VgKi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 과대적합 발생\n",
        "- 손실함수 그래프: 빠르게 과대적합 발생함"
      ],
      "metadata": {
        "id": "A2hHiutDgLCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수, 정확도 그래프 그리기\n",
        "\n",
        "def plot_loss_acc(history, epoch):\n",
        "\n",
        "    loss, val_loss = history.history['loss'], history.history['val_loss']\n",
        "    acc, val_acc = history.history['accuracy'], history.history['val_accuracy']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    axes[0].plot(range(1, epoch + 1), loss, label='Training')\n",
        "    axes[0].plot(range(1, epoch + 1), val_loss, label='Validation')\n",
        "    axes[0].legend(loc='best')\n",
        "    axes[0].set_title('Loss')\n",
        "\n",
        "    axes[1].plot(range(1, epoch + 1), acc, label='Training')\n",
        "    axes[1].plot(range(1, epoch + 1), val_acc, label='Validation')\n",
        "    axes[1].legend(loc='best')\n",
        "    axes[1].set_title('Accuracy')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "h8PdnzMLgPsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_acc(history, 20)"
      ],
      "metadata": {
        "id": "ydsS9w5fcR12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5-2-4 데이터 증강\n",
        "- horizontal_flip 속성: 좌우 방향으로 뒤집음\n",
        "- zoom_range 속성: 이미지를 줌으로 확대\n",
        "- shear_range 속성: 이미지를 반시계 방향으로 밀리도록 변형\n",
        "\n",
        "- 모델 인스턴스를 생ㅅ어하고 훈련, 에포크를 40으로 늘림\n",
        "\n"
      ],
      "metadata": {
        "id": "qkWB7F2qgP-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " 이미지 데이터 제너레이터 정의 (Augmentation 적용)\n",
        "image_gen_aug = ImageDataGenerator(rescale=1/255.,\n",
        "                                   horizontal_flip=True,\n",
        "                                   rotation_range=35,\n",
        "                                   zoom_range=0.2)\n",
        "\n",
        "# flow_from_directory 함수로 폴더에서 이미지 가져와서 제너레이터 객체로 정리\n",
        "train_gen_aug = image_gen_aug.flow_from_directory(train_dir,\n",
        "                                                  batch_size=32,\n",
        "                                                  target_size=(224,224),\n",
        "                                                  classes=['cats','dogs'],\n",
        "                                                  class_mode = 'binary',\n",
        "                                                  seed=2020)\n",
        "\n",
        "valid_gen_aug = image_gen_aug.flow_from_directory(valid_dir,\n",
        "                                                  batch_size=32,\n",
        "                                                  target_size=(224,224),\n",
        "                                                  classes=['cats','dogs'],\n",
        "                                                  class_mode = 'binary',\n",
        "                                                  seed=2020)"
      ],
      "metadata": {
        "id": "706mfBS9h51Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 생성\n",
        "model_aug = build_model()\n",
        "\n",
        "# 모델 컴파일\n",
        "model_aug.compile(optimizer=tf.optimizers.Adam(lr=0.001),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "history_aug = model_aug.fit(train_gen_aug, validation_data=valid_gen_aug, epochs=40)"
      ],
      "metadata": {
        "id": "lP9XRfPscVKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수와 모델의 정확도 그래프 확인"
      ],
      "metadata": {
        "id": "ruj4U7Zjh6OG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수, 정확도 그래프 그리기\n",
        "plot_loss_acc(history_aug, 20)"
      ],
      "metadata": {
        "id": "PNNAQ-7Jh80t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 06 객체 탐지\n",
        "- 이미지를 인식하는 컴퓨터 비전 AI 기술이 가장 많이 응용되는 분야\n",
        "- ex. 자율주행차: 카메라, 또는 센서를 활용해 도로 상황을 파악, 도로를 이동하고 있는 다른 자동차의 움직임 외에도 거리를 횡단하려는 사람들이나 장애물을 식별하고 그 위치를 찾음\n",
        "- 입력 이미지로부터 여러 개의 객체를 찾아내고 각 객체가 무엇을 나타내는 지 분류하는 두 가지 작업을 처리\n",
        "- 이미지에서 각 개체의 위치를 찾아내고 객체를 둘러싸는 네모박스를 그리는데, 객체의 경계를 나타내는 좌표 값을 회귀 문제로 접근함"
      ],
      "metadata": {
        "id": "8fT7oMVxh93k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-1 텐서플로 허브 활용\n",
        "- 텐서플로 허브: 다양한 딥러닝 문제를 해결할 수 있는 검증된 사전 학습 모델을 제공하는 저장소\n",
        "- 제공하는 모델을 그대로 배포해 서빙하는 것도 가능하고, 전이 학습을 거쳐 개별 도메인에 맞게 튜닝한 다음 배포하는 것도 가능"
      ],
      "metadata": {
        "id": "_OYQ7kqyicXQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 텐서플로에서 제공하는 객체 탐지 모델을 사용해 샘플 이미지로부터 객체를 추출하는 작업\n",
        "- 먼저 텐서플로 라이브러리 직접 불러오기"
      ],
      "metadata": {
        "id": "hGiyHf72isGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # tensorflow\n",
        "import tensorflow_hub as tfhub  # tensorflow hub"
      ],
      "metadata": {
        "id": "OLuYk68oi0Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-1-1 샘플 이미지 준비\n",
        "- 이미 학습이 완료된 딥러닝 모델을 사용하므로, 별도의 모델 학습이 필요함x\n",
        "- 서울 강남 지역의 객체 탐지 및 검출"
      ],
      "metadata": {
        "id": "CQ22hFSKi0h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 이미지 다운로드\n",
        "img_path = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Gangnam_Seoul_January_2009.jpg/1280px-Gangnam_Seoul_January_2009.jpg'\n",
        "img = tf.keras.utils.get_file(fname='gangnam', origin=img_path)\n",
        "img = tf.io.read_file(img)   # 파일 객체를 string으로 변환\n",
        "img = tf.image.decode_jpeg(img, channels=3)   # 문자(string)를 숫자(unit8) 텐서로 변환\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)   # 0 ~ 1 범위로 정규화\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "RxcnSl_8jAkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 사전 학습 모델은 배치 크기를 포함해 4차원 텐서를 입력으로 받음\n",
        "- 따라서 가장 앞쪽으로 0번 축으로 새로운 축을 추가"
      ],
      "metadata": {
        "id": "I071ve02jBME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_input = tf.expand_dims(img, 0)  # batch_size추가\n",
        "img_input.shape"
      ],
      "metadata": {
        "id": "n1fUcQGRjJbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-1-2 사전 학습 모델\n",
        "-링크를 텐서플로 허브 라이브러리의 load 함수에 전달해 주면 모델을 불러옴\n",
        "- model 변수에 저장"
      ],
      "metadata": {
        "id": "jxSd99JtjJ2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow Hub에서 모델 가져오기 - FasterRCNN+InceptionResNet V2\n",
        "model = tfhub.load(\"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\")"
      ],
      "metadata": {
        "id": "ybMYja0ljMxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델의 시그니처(용도) 확인"
      ],
      "metadata": {
        "id": "0Ngr6KtwjOAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 시그니처(용도) 확인\n",
        "model.signatures.keys()"
      ],
      "metadata": {
        "id": "MMYxzAMAjOXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 객체 탐지 모델 생성"
      ],
      "metadata": {
        "id": "0hPTlqByjOoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 객체탐지 모델 생성\n",
        "obj_detector = model.signatures['default']\n",
        "obj_detector"
      ],
      "metadata": {
        "id": "EcDaLxEmjPLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-1-3 추론\n",
        "- 객체 탐지 모델에 앞에서 미리 전처리를 통해 준비한 샘플 이미지 입력\n",
        "- 모델은 추론을 거쳐 예측 값을 반환\n",
        "- result 변수의 딕셔너리 키 배열을 확인"
      ],
      "metadata": {
        "id": "snqpzbmHjPY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 이용하여 예측 (추론)\n",
        "result = obj_detector(img_input)\n",
        "result.keys()"
      ],
      "metadata": {
        "id": "G80Jhg31P7xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- detection_boxes: 경계 박스 좌표\n",
        "- detection_class: 검출된 클래스 아이디\n",
        "- detection_score: 검출 스코어"
      ],
      "metadata": {
        "id": "ag2uk8q9P7_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 검출 스코어 점수의 개수를 통해 100개의 객체를 탐지"
      ],
      "metadata": {
        "id": "-XxFTXhqQGW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 탐지한 객체의 개수\n",
        "len(result[\"detection_scores\"])"
      ],
      "metadata": {
        "id": "DrqNiOj8QXQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 검출된 100개의 객체 중 검출 스코어가 0.1보다 큰 경우만 경계 박스와 예측 클래스를 시각화\n",
        "- 최대 10개의 객체만 표시되도록 설정"
      ],
      "metadata": {
        "id": "BhqpsS-EQXYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 객체 탐지 결과를 시각화\n",
        "boxes = result[\"detection_boxes\"]    # Bounding Box 좌표 예측값\n",
        "labels = result[\"detection_class_entities\"]   # 클래스 값\n",
        "scores = result[\"detection_scores\"]   # 신뢰도 (confidence)\n",
        "\n",
        "# 샘플 이미지 가로 세로 크기\n",
        "img_height, img_width = img.shape[0], img.shape[1]\n",
        "\n",
        "# 탐지할 최대 객체의 수\n",
        "obj_to_detect = 10\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(min(obj_to_detect, boxes.shape[0])):\n",
        "    if scores[i] >= 0.2:\n",
        "        (ymax, xmin, ymin, xmax) = (boxes[i][0]*img_height, boxes[i][1]*img_width,\n",
        "                                    boxes[i][2]*img_height, boxes[i][3]*img_width)\n",
        "\n",
        "        plt.imshow(img)\n",
        "        plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin],\n",
        "                 color='yellow', linewidth=2)\n",
        "\n",
        "        class_name = labels[i].numpy().decode('utf-8')\n",
        "        infer_score = int(scores[i].numpy()*100)\n",
        "        annotation = \"{}: {}%\".format(class_name, infer_score)\n",
        "        plt.text(xmin+10, ymax+20, annotation,\n",
        "                 color='white', backgroundcolor='blue', fontsize=10)"
      ],
      "metadata": {
        "id": "DKj3XvG4Qd2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-2 YOLO 객체 탐지\n",
        "- YOLO는 경계 박스와 예측 클래스를 서로 다른 문제로 다루지 않고 하나의 회귀 문제로 접근하는 개념\n",
        "- 하나의 신경망이 한 번만 계산해 두 가지 일을 한꺼번에 처리\n",
        "- 즉, 속도가 매우 빠르다"
      ],
      "metadata": {
        "id": "Pgj9sEepQfTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-2-1 Darknet YOLO 모델 추론하기\n",
        "- 개인의 로컬 PC 환경에서 학습하는 것은 불가능(시간, 성능 등의 문제)\n",
        "- 하지만, Darknet에서 제공하는 사전 학습 모델을 활용하면 일반 PC 환경에서도 YOLO 뿐만 아닌 ResNet 등 다양한 딥러닝 모델을 실행할수 있다.\n",
        "\n",
        "1. 깃허브 저장소를 코랩 환경으로 다운로드 받음 -> darknet 폴더가 생성되는 것을 확인\n",
        "2. 객체를 탐지할 샘플 이미지를 업로드"
      ],
      "metadata": {
        "id": "ZkTOQ5PsR6Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 깃헙 저장소 복제\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "metadata": {
        "id": "bm89yIj2TYPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CPU를 사용할 수 있도록 Darknet의 Makefile을 수정하고, Darknet을 생성"
      ],
      "metadata": {
        "id": "yUyCbvXbTYox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 활성화\n",
        "%cd darknet\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "\n",
        "# Darknet 생성\n",
        "!make"
      ],
      "metadata": {
        "id": "NrqxHo7zTfnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 가중치를 가져옴"
      ],
      "metadata": {
        "id": "3ArOSffSTgYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 가중치 가져옴\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3"
      ],
      "metadata": {
        "id": "U_b2gwXaTh93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 업로드한 샘플 이미지를 출력해서 확인, 텐서플로 허브에서 사용했던 서울 강남 도로 사진"
      ],
      "metadata": {
        "id": "pOyEgcgpTiHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "img = tf.io.read_file('/content/gangnam.jpg')\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "CYvu598lTp9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Darknet을 실행하여 샘플 이미지에 대한 객체 탐지를 추론한다.\n",
        "- 객체를 추출하고 예측 확률을 계산\n",
        "- 샘플 이미지의 코랩 파일 경로를 마지막에 추가"
      ],
      "metadata": {
        "id": "lCwq0ENATqN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Darknet 실행\n",
        "!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights /content/gangnam.jpeg # 노트북이라 GPU가 없어 결과 생략"
      ],
      "metadata": {
        "id": "u_Pe9ymyT20O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "#img = tf.io.read_file('/content/darknet/predictions.jpg')\n",
        "#img = tf.image.decode_jpeg(img, channels=3)\n",
        "#img = tf.image.convert_image_dtype(img, tf.float32)   #\n",
        "#plt.imshow(img)"
      ],
      "metadata": {
        "id": "U4-aLVdAcxPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6-2-2 나만의 YOLO 모델 생성\n",
        "- Darknet 수준의 YOLO 모델을 개인이 학습하기에는 컴퓨터 리소스가 너무 많이 필요하고 시간도 너무 많이 걸린다는 단점이 존재\n",
        "- 검은 바탕에 간단한 도형 3개만 탐지하는 YOLO 모델을 만들어보고, YOLO 모델을 더 쉽게 이해하자\n",
        "- 앞의 그림을 보면 YOLO 논문에서는 이미지를 가로, 세로 각각 7개의 셀로 나눠 총 49셀을 기본으로 하지만, 우린 3*3 으로 단순화\n",
        "- 한 셀당 1개의 박스를 그리는 방ㅅ기으로 단순화\n",
        "- 탐지할 객체의 종류인 class도 3개로 줄여 구현"
      ],
      "metadata": {
        "id": "qS5ZfxeIUr9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 패키지를 임포트 함\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 파라미터 설정\n",
        "\n",
        "# 이미지 크기\n",
        "width_size = 256\n",
        "height_size = 256\n",
        "channel_size = 3\n",
        "img_size = (width_size,hight_size,channel_size)\n",
        "\n",
        "# 이미지를 나눌 크기\n",
        "cell_num = 3\n",
        "\n",
        "# 찾고자 하는 객체 개수\n",
        "class_num = 3\n",
        "\n",
        "# 한셀에 그릴 박스 수\n",
        "anchor_num = 1\n",
        "label_num = anchor_num * (5 + class_num)\n",
        "\n",
        "# 학습 수\n",
        "epoch_num = 20000\n",
        "\n",
        "# 로스 비중\n",
        "loss_p_rate = 1.0\n",
        "loss_cod_rate = 5.0\n",
        "loss_c_rate = 1.0\n",
        "loss_p_no_rate = 0.5"
      ],
      "metadata": {
        "id": "DRts-zivUrq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CV2를 이용해 랜덤한 위치에 3개의 도형 이미지를 그림\n",
        "- 해당 이미지의 위치를 찾아 경계 박스로 나타내고, 정답 클래스 레이블까지 반환하는 함수를 정의"
      ],
      "metadata": {
        "id": "J3clZ7nZWGqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤하게 도형을 그리고, 실제 정답 값을 생성하는 함수 정의\n",
        "# 0.png / 1.png / 2.png 파일이 필요함\n",
        "\n",
        "def make_img_label():\n",
        "    img = np.zeros((height_size + 400, width_size + 400, channel_size))\n",
        "    label = np.zeros((cell_num, cell_num, label_num))\n",
        "    num_shape = np.random.randint(1,4)\n",
        "    i = np.random.choice(range(cell_num), num_shape, replace=False)\n",
        "    j = np.random.choice(range(cell_num), num_shape, replace=False)\n",
        "\n",
        "    img_0 = cv2.imread('/content/0.png')\n",
        "    img_1 = cv2.imread('/content/1.png')\n",
        "    img_2 = cv2.imread('/content/2.png')\n",
        "\n",
        "    for n_h in range(num_shape):\n",
        "        row = i[n_h]\n",
        "        col = j[n_h]\n",
        "        shape_type = np.random.randint(0, class_num)\n",
        "        x_rate = np.random.rand()\n",
        "        y_rate = np.random.rand()\n",
        "        w_rate = np.random.rand() * 0.3 + 0.1\n",
        "        h_rate = np.random.rand() * 0.3 + 0.1\n",
        "\n",
        "        label[row, col] = [1, x_rate, y_rate, w_rate, h_rate, 0, 0, 0]\n",
        "        label[row, col, 5 + shape_type] = 1\n",
        "        x = int(x_rate * width_size / cell_num + col * width_size / cell_num)\n",
        "        y = int(y_rate * height_size / cell_num + row * height_size / cell_num)\n",
        "        w = int(w_rate * width_size / 2) * 2\n",
        "        h = int(h_rate * height_size / 2) * 2\n",
        "        if(shape_type == 0):\n",
        "            input_img = cv2.resize(img_0, (w,h))\n",
        "        if(shape_type == 1):\n",
        "            input_img = cv2.resize(img_1, (w,h))\n",
        "        if(shape_type == 2):\n",
        "            input_img = cv2.resize(img_2, (w,h))\n",
        "        img[y-int(h/2)+200 : y+int(h/2)+200, x-int(w/2)+200 : x+int(w/2)+200] = input_img\n",
        "    img = img[200 : 200+height_size, 200 : 200+width_size]\n",
        "\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "K_ROqsCOWOa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = make_img_label()\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "X3kuUD7xc3YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 실습을 위해 앞에서 생성한 이미지와 클래스를 입력해주면 탐지한 이미지에 박스를 그려주는 함수를 정의\n",
        "- 함수를 실행하면 경계 박스를 찾아서 표시"
      ],
      "metadata": {
        "id": "dt0cCnQVWPxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지와 정답(혹은 예측값)을 넣으면 박스를 그려주는 함수 정의\n",
        "# 임계값 th 설정 (객체가 있다는 확률이 th이상일 때만 박스 생성)\n",
        "def show_box(img,label,th=0.3):\n",
        "    b_img = np.zeros((hight_size+400,width_size+400,3))\n",
        "    b_img[200:200+hight_size,200:200+width_size] = img\n",
        "    for i in range(cell_num):\n",
        "        for j in range(cell_num):\n",
        "            if(label[i,j,0] > th):\n",
        "                x_rate = label[i,j,1]\n",
        "                y_rate = label[i,j,2]\n",
        "                w_rate = label[i,j,3]\n",
        "                h_rate = label[i,j,4]\n",
        "                shape_type=np.argmax(label[i,j,5:])\n",
        "                if(shape_type==0):\n",
        "                    line_color = [0,0,255]\n",
        "                if(shape_type==1):\n",
        "                    line_color = [255,0,0]\n",
        "                if(shape_type==2):\n",
        "                    line_color = [0,255,0]\n",
        "                x = int(x_rate * width_size/3 + j * width_size/3)\n",
        "                y = int(y_rate * hight_size/3 + i * hight_size/3)\n",
        "                w = int(w_rate * width_size/2) * 2 + 20\n",
        "                h = int(h_rate * hight_size/2) * 2 + 20\n",
        "\n",
        "                cv2.rectangle(b_img,(x-int(w/2)+200,y-int(h/2)+200),(x+int(w/2)+200,y+int(h/2)+200),line_color)\n",
        "\n",
        "    b_img = b_img[200:200+hight_size,200:200+width_size]\n",
        "    return b_img\n",
        "cv2_imshow(show_box(img,label))"
      ],
      "metadata": {
        "id": "5d3YEt8UWXPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 객체 탐지 모델이 어느 정도 성능을 갖기 위해서는 복잡한 구조로 구현되어야 함\n",
        "- 전이 학습 방법을 이용해 이미지 특징을 추출하는 데 좋은 성능을 갖는 모델을 기본으로 활용하는 것이 좋음\n",
        "- 다음 코드에서는 VGG16 모델을 베이스로 사용하고, Conv2D층과 Dense 레이어를 마지막 객체 탐지 분류기로 설정\n",
        "- 모델 구조를 요약해서 확인"
      ],
      "metadata": {
        "id": "4jEc6kp9WXd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16모델을 베이스로 마지막 부분만 수정하는 모델 생성 (전이 학습)\n",
        "vgg_model = tf.keras.applications.VGG16(include_top=False,input_shape=img_size)\n",
        "vgg_model.trainable=False\n",
        "i=tf.keras.Input(shape=img_size)\n",
        "out=tf.keras.layers.Lambda((lambda x : x/255.))(i)\n",
        "out = vgg_model(out)\n",
        "out = tf.keras.layers.Conv2D(256,3,padding='same')(out)\n",
        "out = tf.keras.layers.Conv2D(128,3,padding='same')(out)\n",
        "out = tf.keras.layers.Conv2D(64,3,padding='same')(out)\n",
        "out = tf.keras.layers.Flatten()(out)\n",
        "out = tf.keras.layers.Dense(1024,activation='relu')(out)\n",
        "out = tf.keras.layers.Dense(3*3*8,activation='sigmoid')(out)\n",
        "out = tf.keras.layers.Reshape((3,3,8))(out)\n",
        "yolo_model = tf.keras.Model(inputs=[i],outputs=[out])\n",
        "opt = tf.keras.optimizers.Adam(0.00001)\n",
        "\n",
        "# 모델 요약\n",
        "yolo_model.summary()"
      ],
      "metadata": {
        "id": "ZDDKGBLFWrA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이미지를 총 9개의 셀로 나누고 셀마다 학습을 진행\n",
        "- 객체가 있는 셀의 경우 확률/박스위치 및 크기/클래스 종류 모두 학습을 진행\n",
        "- 객체가 없는 셀은 객체가 없는 확률만 학습\n",
        "- 각 loss는 미리 정한 비중을 곱하고 전체를 더해 최종 loss를 만들어 모델 학습"
      ],
      "metadata": {
        "id": "W-jEgBPtWrlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습과정을 동영상으로 기록\n",
        "fcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
        "out=cv2.VideoWriter('hjk_yolo.avi',fcc,1.0,(width_size,hight_size))\n",
        "for e in range(epoch_num):\n",
        "    img,label = make_img_label()\n",
        "    img = np.reshape(img,(1,hight_size,width_size,3))\n",
        "    label = np.reshape(label,(1,3,3,8))\n",
        "    loss_p_list=[]\n",
        "    loss_cod_list = []\n",
        "    loss_c_list = []\n",
        "    loss_p_no_list = []\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = yolo_model(img)\n",
        "        # 이미지를 구분한 셀을 탐험\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                # 해당 셀에 객체가 있을 경우는 확률, 박스 크기, 클래스까지 모두 Loss로 계산\n",
        "                if(label[0,i,j,0]==1):\n",
        "                    loss_p_list.append(tf.square(label[0,i,j,0]-pred[0,i,j,0]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,1]-pred[0,i,j,1]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,2]-pred[0,i,j,2]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,3]-pred[0,i,j,3]))\n",
        "                    loss_cod_list.append(tf.square(label[0,i,j,4]-pred[0,i,j,4]))\n",
        "                    loss_c_list.append(tf.square(label[0,i,j,5]-pred[0,i,j,5]))\n",
        "                    loss_c_list.append(tf.square(label[0,i,j,6]-pred[0,i,j,6]))\n",
        "                    loss_c_list.append(tf.square(label[0,i,j,7]-pred[0,i,j,7]))\n",
        "                # 해당 셀에 객체가 없을 경우 객체가 없을 확률만 Loss로 계산\n",
        "                else:\n",
        "                    loss_p_no_list.append(tf.square(label[0,i,j,0]-pred[0,i,j,0]))\n",
        "        loss_p=tf.reduce_mean(loss_p_list)\n",
        "        loss_cod =tf.reduce_mean(loss_cod_list)\n",
        "        loss_c = tf.reduce_mean(loss_c_list)\n",
        "        loss_p_no = tf.reduce_mean(loss_p_no_list)\n",
        "        # 각 Loss를 비중을 곱해 더해 최종 Loss를 계산\n",
        "        loss = loss_p_rate * loss_p + loss_cod_rate * loss_cod + loss_c_rate * loss_c + loss_p_no_rate * loss_p_no\n",
        "    # Loss에 대한 Grad를 구하고, 각 파라미터를 업데이트\n",
        "    vars = yolo_model.trainable_variables\n",
        "    grad = tape.gradient(loss, vars)\n",
        "    opt.apply_gradients(zip(grad, vars))\n",
        "    # 100번 마다 동영상에 이미지를 기록한다\n",
        "    if(e%100==0):\n",
        "        img = np.reshape(img,(256,256,3))\n",
        "        label = pred.numpy()\n",
        "        label = np.reshape(label,(3,3,8))\n",
        "        sample_img = np.uint8(show_box(img,label))\n",
        "        out.write(sample_img)\n",
        "    print(e,\"완료\",loss.numpy())\n",
        "out.release()"
      ],
      "metadata": {
        "id": "zm1A2AhIYkM2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}